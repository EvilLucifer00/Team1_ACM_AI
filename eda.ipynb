{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYaGUQavHdlddd2um6IrX9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EvilLucifer00/Team1_ACM_AI/blob/main/eda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjLE5LVA8FOF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('train.csv')\n",
        "df.shape"
      ],
      "metadata": {
        "id": "d_0cXHyb8cq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "CATEGORY_KEYWORDS = {\n",
        "    # Food\n",
        "    \"chocolate\": [\"chocolate\", \"cocoa\", \"dark choc\", \"milk choc\"],\n",
        "    \"bread\": [\"bread\", \"bun\", \"loaf\", \"bagel\", \"brioche\", \"croissant\"],\n",
        "    \"butter\": [\"butter\", \"margarine\", \"ghee\", \"spread\"],\n",
        "    \"jam\": [\"jam\", \"jelly\", \"marmalade\", \"preserve\"],\n",
        "    \"coffee\": [\"coffee\", \"espresso\", \"latte\", \"mocha\", \"cappuccino\"],\n",
        "    \"tea\": [\"tea\", \"chai\", \"matcha\", \"oolong\", \"herbal\"],\n",
        "    \"milk\": [\"milk\", \"dairy\", \"cream\", \"creamer\"],\n",
        "    \"syrup\": [\"syrup\", \"honey\", \"molasses\", \"maple\"],\n",
        "    \"snack\": [\"snack\", \"chips\", \"crackers\", \"popcorn\", \"nuts\", \"pretzel\"],\n",
        "    \"spice\": [\"spice\", \"seasoning\", \"masala\", \"herb\"],\n",
        "    \"sauce\": [\"sauce\", \"ketchup\", \"mustard\", \"mayonnaise\", \"dressing\", \"salsa\"],\n",
        "    \"pasta\": [\"pasta\", \"noodle\", \"spaghetti\", \"macaroni\", \"lasagna\"],\n",
        "    \"rice\": [\"rice\", \"grain\", \"basmati\", \"brown rice\"],\n",
        "    \"biscuit\": [\"biscuit\", \"cookie\", \"cracker\", \"shortbread\"],\n",
        "    \"juice\": [\"juice\", \"nectar\", \"squash\"],\n",
        "    \"oil\": [\"oil\", \"olive\", \"sunflower\", \"canola\", \"vegetable\"],\n",
        "    \"cereal\": [\"cereal\", \"granola\", \"oats\", \"muesli\"],\n",
        "    \"candy\": [\"candy\", \"sweet\", \"toffee\", \"gum\", \"mint\"],\n",
        "    \"protein\": [\"protein\", \"whey\", \"supplement\", \"shake\", \"powder\"],\n",
        "    \"vinegar\": [\"vinegar\", \"acetic\"],\n",
        "    \"pickle\": [\"pickle\", \"relish\", \"gherkin\"],\n",
        "    \"drink\": [\"drink\", \"beverage\", \"soda\", \"cola\", \"sparkling\", \"energy drink\", \"juice\"],\n",
        "    \"baking\": [\"flour\", \"yeast\", \"baking powder\", \"cornstarch\", \"icing\"],\n",
        "    \"cheese\": [\"cheese\", \"mozzarella\", \"cheddar\", \"parmesan\"],\n",
        "    \"frozen\": [\"frozen\", \"ice cream\", \"frozen meal\"],\n",
        "    \"soup\": [\"soup\", \"broth\", \"stock\"],\n",
        "    \"egg\": [\"egg\", \"eggs\"],\n",
        "    \"meat\": [\"meat\", \"chicken\", \"mutton\", \"pork\", \"beef\", \"fish\"],\n",
        "    \"vegetable\": [\"vegetable\", \"veggie\", \"spinach\", \"tomato\", \"onion\", \"potato\"],\n",
        "    \"fruit\": [\"fruit\", \"apple\", \"banana\", \"mango\", \"berry\", \"orange\", \"grape\"],\n",
        "\n",
        "    # Non-food\n",
        "    \"detergent\": [\"detergent\", \"washing powder\", \"laundry\", \"fabric softener\"],\n",
        "    \"cleaner\": [\"cleaner\", \"disinfectant\", \"bleach\", \"toilet\", \"floor\", \"bathroom\"],\n",
        "    \"dishwashing\": [\"dishwash\", \"dish soap\", \"utensil cleaner\"],\n",
        "    \"soap\": [\"soap\", \"bar soap\", \"handwash\"],\n",
        "    \"shampoo\": [\"shampoo\", \"conditioner\", \"hair wash\"],\n",
        "    \"toothpaste\": [\"toothpaste\", \"tooth powder\", \"mouthwash\"],\n",
        "    \"skincare\": [\"lotion\", \"cream\", \"moisturizer\", \"serum\", \"face wash\", \"cleanser\"],\n",
        "    \"cosmetic\": [\"makeup\", \"lipstick\", \"foundation\", \"mascara\", \"eyeliner\", \"nail polish\"],\n",
        "    \"deodorant\": [\"deodorant\", \"perfume\", \"body spray\", \"fragrance\"],\n",
        "    \"sanitary\": [\"sanitary\", \"napkin\", \"pad\", \"tampon\"],\n",
        "    \"baby_care\": [\"baby\", \"infant\", \"diaper\", \"wipes\", \"baby food\"],\n",
        "    \"pet_food\": [\"dog food\", \"cat food\", \"pet treat\", \"bird feed\"],\n",
        "    \"stationery\": [\"pen\", \"pencil\", \"notebook\", \"eraser\", \"marker\", \"paper\"],\n",
        "    \"home_supplies\": [\"tissue\", \"napkin\", \"foil\", \"wrap\", \"bag\", \"cup\", \"plate\"],\n",
        "    \"electronics\": [\"battery\", \"bulb\", \"charger\", \"adapter\", \"cable\"],\n",
        "}\n",
        "\n",
        "SPELLING_CORRECTIONS = {\n",
        "    # Weight/volume\n",
        "    \"ouunce\": \"ounce\",\n",
        "    \"ouu?nce\": \"ounce\",\n",
        "    \"ounc\": \"ounce\",\n",
        "    \"grm\": \"gram\",\n",
        "    \"graam\": \"gram\",\n",
        "    \"gramme\": \"gram\",\n",
        "    \"grams\": \"gram\",\n",
        "    \"kilo\": \"kg\",\n",
        "    \"kgr\": \"kg\",\n",
        "    \"mililitre\": \"ml\",\n",
        "    \"millilitre\": \"ml\",\n",
        "    \"milliliter\": \"ml\",\n",
        "    \"milileter\": \"ml\",\n",
        "    \"milil\": \"ml\",\n",
        "    \"liter\": \"l\",\n",
        "    \"litre\": \"l\",\n",
        "    \"litr\": \"l\",\n",
        "    \"lt\": \"l\",\n",
        "    \"ltr\": \"l\",\n",
        "    # Quantity\n",
        "    \"pcs\": \"pieces\",\n",
        "    \"pce\": \"pieces\",\n",
        "    \"peices\": \"pieces\",\n",
        "    \"peece\": \"pieces\",\n",
        "    \"cnt\": \"count\",\n",
        "    \"pk\": \"pack\",\n",
        "    # Colour\n",
        "    \"colr\": \"colour\",\n",
        "    \"clr\": \"colour\",\n",
        "    \"clour\": \"colour\",\n",
        "    # Misc\n",
        "    \"flavor\": \"flavour\",\n",
        "    \"flavr\": \"flavour\",\n",
        "    \"favr\": \"flavour\",\n",
        "}\n",
        "\n",
        "def normalize_text(text):\n",
        "    \"\"\"Lowercase and fix common spelling issues, including fl oz variants.\"\"\"\n",
        "    text = str(text).lower()\n",
        "\n",
        "    # Normalize fluid ounce variants before other corrections\n",
        "    text = re.sub(r\"fl[\\.\\s]*oz|fluid[\\s]*ounce[s]?\", \"fl_oz\", text)\n",
        "\n",
        "    for wrong, correct in SPELLING_CORRECTIONS.items():\n",
        "        text = re.sub(rf\"\\b{wrong}\\b\", correct, text)\n",
        "    return text\n",
        "\n",
        "\n",
        "def detect_category(text):\n",
        "    \"\"\"Detect product category based on keywords.\"\"\"\n",
        "    for category, keywords in CATEGORY_KEYWORDS.items():\n",
        "        for kw in keywords:\n",
        "            if re.search(rf\"\\b{kw}\\b\", text):\n",
        "                return category\n",
        "    return \"other\"\n",
        "\n",
        "def extract_product_info(text):\n",
        "    \"\"\"Extract structured info (weight, volume, brand, category, etc.).\"\"\"\n",
        "    text = normalize_text(text)\n",
        "    info = {}\n",
        "\n",
        "    # Item Name\n",
        "    match = re.search(r\"item\\s*name\\s*:\\s*(.*)\", text)\n",
        "    info[\"item_name\"] = match.group(1).strip() if match else text.strip()\n",
        "\n",
        "    # Weight\n",
        "    match = re.search(r\"(\\d+(?:\\.\\d+)?)\\s*(g|gram|kg|oz|ounce|lb)\", text)\n",
        "    info[\"weight_value\"] = match.group(1) if match else np.nan\n",
        "    info[\"weight_unit\"] = match.group(2) if match else \"unknown\"\n",
        "\n",
        "    # Volume\n",
        "    match = re.search(r\"(\\d+(?:\\.\\d+)?)\\s*(ml|l|fl_oz)\", text)\n",
        "    info[\"volume_value\"] = match.group(1) if match else np.nan\n",
        "    info[\"volume_unit\"] = match.group(2) if match else \"unknown\"\n",
        "\n",
        "    # Imported from\n",
        "    match = re.search(r\"imported\\s+from\\s+([a-z ]+)\", text)\n",
        "    info[\"imported_from\"] = match.group(1).strip() if match else np.nan\n",
        "\n",
        "    # Colour\n",
        "    match = re.search(r\"colour\\s*:\\s*([a-z ]+)\", text)\n",
        "    info[\"colour\"] = match.group(1).strip() if match else np.nan\n",
        "\n",
        "    # Pack and quantity parsing\n",
        "\n",
        "    pack_match = re.search(r\"(\\d+)\\s*[- ]*(?:pack|packs?)\", text)\n",
        "    combo_match = re.search(r\"(\\d+)\\s*[x×]\\s*(\\d+)\\s*(g|gram|kg|ml|l|fl_oz|oz|ounce)?\", text)\n",
        "    count_match = re.search(r\"(\\d+)\\s*(?:pieces?|count|pcs|bottles|units|bars|sticks|pouches|bags)\", text)\n",
        "\n",
        "    if combo_match:\n",
        "        # \"12 x 30g\" → 12 packs, 30 per pack\n",
        "        info[\"pack_count\"] = int(combo_match.group(1))\n",
        "        info[\"quantity_per_pack\"] = int(combo_match.group(2))\n",
        "    elif pack_match and count_match:\n",
        "        # \"3 pack of 6 bars\" → 3 packs, 6 per pack\n",
        "        info[\"pack_count\"] = int(pack_match.group(1))\n",
        "        info[\"quantity_per_pack\"] = int(count_match.group(1))\n",
        "    elif pack_match:\n",
        "        # \"3-pack\" → 3 packs of 1\n",
        "        info[\"pack_count\"] = int(pack_match.group(1))\n",
        "        info[\"quantity_per_pack\"] = 1\n",
        "    elif count_match:\n",
        "        # \"6 count\" → 1 pack of 6\n",
        "        info[\"pack_count\"] = 1\n",
        "        info[\"quantity_per_pack\"] = int(count_match.group(1))\n",
        "    else:\n",
        "        # Default → single item\n",
        "        info[\"pack_count\"] = 1\n",
        "        info[\"quantity_per_pack\"] = 1\n",
        "\n",
        "\n",
        "    # Flavour\n",
        "    match = re.search(r\"flavour\\s*:\\s*([a-z ]+)\", text)\n",
        "    info[\"flavour\"] = match.group(1).strip() if match else np.nan\n",
        "\n",
        "    # Brand heuristic (first words before descriptors)\n",
        "    brand_guess = re.match(r\"([a-z]+(?:\\s+[a-z]+)?)\", info[\"item_name\"])\n",
        "    info[\"brand_name\"] = brand_guess.group(1) if brand_guess else np.nan\n",
        "\n",
        "    # Category\n",
        "    info[\"category\"] = detect_category(text)\n",
        "\n",
        "    return info\n",
        "\n",
        "\n",
        "extracted = df[\"catalog_content\"].apply(extract_product_info).apply(pd.Series)\n",
        "\n",
        "\n",
        "result_full = pd.concat([df[[\"sample_id\", \"price\"]], extracted], axis=1)\n",
        "print(result_full.head(10))\n",
        "\n",
        "\n",
        "result_full.to_csv(\"extracted_features_full.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "Ip_BPm638x74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_full[\"price\"].skew()"
      ],
      "metadata": {
        "id": "x_TxI5j19bXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def standardize_units(row):\n",
        "    weight_val = row.get(\"weight_value\", np.nan)\n",
        "    weight_unit = str(row.get(\"weight_unit\", \"\")).lower()\n",
        "    volume_val = row.get(\"volume_value\", np.nan)\n",
        "    volume_unit = str(row.get(\"volume_unit\", \"\")).lower()\n",
        "\n",
        "    weight_g = np.nan\n",
        "    volume_ml = np.nan\n",
        "\n",
        "    #Weight\n",
        "    if pd.notna(weight_val):\n",
        "        try:\n",
        "            value = float(weight_val)\n",
        "            if weight_unit in [\"g\", \"gram\", \"grams\"]:\n",
        "                weight_g = value\n",
        "            elif weight_unit in [\"kg\", \"kilogram\"]:\n",
        "                weight_g = value * 1000\n",
        "            elif weight_unit in [\"oz\", \"ounce\"]:\n",
        "                weight_g = value * 28.3495\n",
        "            elif weight_unit in [\"lb\", \"pound\"]:\n",
        "                weight_g = value * 453.592\n",
        "        except ValueError:\n",
        "            pass\n",
        "\n",
        "    # --- Volume ---\n",
        "    if pd.notna(volume_val):\n",
        "        try:\n",
        "            value = float(volume_val)\n",
        "            if volume_unit in [\"ml\", \"millilitre\", \"milliliter\"]:\n",
        "                volume_ml = value\n",
        "            elif volume_unit in [\"l\", \"litre\", \"liter\"]:\n",
        "                volume_ml = value * 1000\n",
        "            elif volume_unit in [\"fl_oz\", \"fl oz\", \"fluid ounce\"]:\n",
        "                volume_ml = value * 29.5735\n",
        "        except ValueError:\n",
        "            pass\n",
        "\n",
        "    return pd.Series({\"weight_g\": weight_g, \"volume_ml\": volume_ml})\n",
        "\n",
        "result_full[[\"weight_g\", \"volume_ml\"]] = result_full.apply(standardize_units, axis=1)\n",
        "\n",
        "\n",
        "\n",
        "def compute_cost_features(row):\n",
        "    cost_per_weight = np.nan\n",
        "    cost_per_volume = np.nan\n",
        "    total_weight = np.nan\n",
        "    total_volume = np.nan\n",
        "\n",
        "    #Total weight and volume considering pack/quantity\n",
        "    if pd.notna(row[\"weight_g\"]):\n",
        "        total_weight = row[\"weight_g\"] * row[\"pack_count\"] * row[\"quantity_per_pack\"]\n",
        "        cost_per_weight = row[\"price\"] / total_weight if total_weight > 0 else np.nan\n",
        "\n",
        "    if pd.notna(row[\"volume_ml\"]):\n",
        "        total_volume = row[\"volume_ml\"] * row[\"pack_count\"] * row[\"quantity_per_pack\"]\n",
        "        cost_per_volume = row[\"price\"] / total_volume if total_volume > 0 else np.nan\n",
        "\n",
        "    return pd.Series({\n",
        "        \"total_weight_g\": total_weight,\n",
        "        \"total_volume_ml\": total_volume,\n",
        "        \"cost_per_weight\": cost_per_weight,\n",
        "        \"cost_per_volume\": cost_per_volume\n",
        "    })\n",
        "\n",
        "result_full[[\"total_weight_g\", \"total_volume_ml\", \"cost_per_weight\", \"cost_per_volume\"]] = result_full.apply(compute_cost_features, axis=1)\n"
      ],
      "metadata": {
        "id": "Xb8Krm519frv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_full['total_qty'] = (\n",
        "    result_full['pack_count'].fillna(1).astype(float).replace(0, 1) *\n",
        "    result_full['quantity_per_pack'].fillna(1).astype(float).replace(0, 1)\n",
        ")\n",
        "result_full['unit_price'] = result_full['price'].astype(float) / result_full['total_qty']"
      ],
      "metadata": {
        "id": "bpAQAtZv9xge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_full.tail()"
      ],
      "metadata": {
        "id": "t_iIA99b9zz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_full[\"unit_price\"].skew()"
      ],
      "metadata": {
        "id": "rdU7BqaE96wO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_full['unit_price'].isna().sum()\n"
      ],
      "metadata": {
        "id": "J-b8dPrx-Kbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_full['log_unit_price'] = np.log1p(result_full['unit_price'])\n",
        "result_full[\"log_unit_price\"].skew()"
      ],
      "metadata": {
        "id": "7L6nAKQF-PtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_full.to_csv(\"cleaned_train_data.csv\", index=False)"
      ],
      "metadata": {
        "id": "DlaJXOis-S9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dff=pd.read_csv('test.csv')\n"
      ],
      "metadata": {
        "id": "R4MZP8Cm-X_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def total(row):\n",
        "\n",
        "    total_weight = np.nan\n",
        "    total_volume = np.nan\n",
        "\n",
        "    # Total weight and volume considering pack and quantity\n",
        "    if pd.notna(row[\"weight_g\"]):\n",
        "        total_weight = row[\"weight_g\"] * row[\"pack_count\"] * row[\"quantity_per_pack\"]\n",
        "\n",
        "\n",
        "    if pd.notna(row[\"volume_ml\"]):\n",
        "        total_volume = row[\"volume_ml\"] * row[\"pack_count\"] * row[\"quantity_per_pack\"]\n",
        "\n",
        "\n",
        "    return pd.Series({\n",
        "        \"total_weight_g\": total_weight,\n",
        "        \"total_volume_ml\": total_volume\n",
        "    })"
      ],
      "metadata": {
        "id": "N2RTL4MV-X7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "extracted = dff[\"catalog_content\"].apply(extract_product_info).apply(pd.Series)\n",
        "\n",
        "\n",
        "test_1 = pd.concat([df[[\"sample_id\"]], extracted], axis=1)\n",
        "\n",
        "\n",
        "\n",
        "test_1[[\"weight_g\", \"volume_ml\"]]=test_1.apply(standardize_units, axis=1)\n",
        "test_1[[\"total_weight_g\", \"total_volume_ml\"]] = test_1.apply(total, axis=1)\n",
        "\n",
        "test_1['total_qty'] = (\n",
        "    test_1['pack_count'].fillna(1).astype(float).replace(0, 1) *\n",
        "    test_1['quantity_per_pack'].fillna(1).astype(float).replace(0, 1)\n",
        ")"
      ],
      "metadata": {
        "id": "8iVOPfoi-X5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_1.to_csv(\"cleaned_test_data.csv\", index=False)"
      ],
      "metadata": {
        "id": "shlA0qT--X2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8n-zY1gX-1ZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lluFOryn-1Vf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A47ChJVe-1R9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JT81lcQ0-1Oa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HEsQoN6m-1L_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IydLYDS6-1JX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fzve_rTz-1Gm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y_W-SDiD-1Du"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6jiMrNba-1BK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZLHrsj4g-0-U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}